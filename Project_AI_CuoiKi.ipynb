{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_AI_CuoiKi",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v5tc72oRirJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img,ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path=\"/content/drive/MyDrive/People_CNN/test/\"\n",
        "train_path=\"/content/drive/MyDrive/People_CNN/train/\"\n"
      ],
      "metadata": {
        "id": "MDyYibOFYr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.utils import np_utils\n",
        "direc = '/content/drive/MyDrive/People_CNN/'\n",
        "features, labels, indexlabel = list(), list(),list()\n",
        "count=0\n",
        "num = 0\n",
        "\n",
        "for i in os.listdir(direc):\n",
        "    path = os.path.join(direc, i)\n",
        "    labels.append(i)\n",
        "    num = 0\n",
        "    for j in os.listdir(path):\n",
        "        img_path = os.path.join(path, j)\n",
        "        img = cv2.imread(img_path)\n",
        "        \n",
        "        if (cv2.imread(img_path)).shape[1] > 100 and (cv2.imread(img_path)).shape[0]>100:  \n",
        "          print(img.shape)     \n",
        "          img = cv2.resize(img,(100,100), interpolation=cv2.INTER_AREA)\n",
        "          img = img_to_array(img)       \n",
        "          img = img.reshape(100,100,3)\n",
        "          img = img.astype('float32')\n",
        "          img = img/255\n",
        "          indexlabel.append(count)\n",
        "          features.append(img)  \n",
        "          num+=1\n",
        "          print(num)\n",
        "          if num == 250 :\n",
        "            break\n",
        "\n",
        "    count = count+1\n",
        "  \n",
        "\n",
        "x_train = np.asarray(features)\n",
        "y_train = np.asarray(indexlabel)\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_train = np_utils.to_categorical(y_train,8)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_train,y_train, test_size = 0.3, random_state= 700)\n",
        "\n"
      ],
      "metadata": {
        "id": "trFrFCNrDy5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image_samples(train_gen)"
      ],
      "metadata": {
        "id": "-TP0XZdHYkpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BeK5pTMyWYT",
        "outputId": "22c9c771-3f5b-4634-c927-5f5a988ae271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Knee', 'Hand', 'Nose', 'Ear', 'Foot', 'Eye', 'Shoulders', 'Elbow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOWxC17sApik",
        "outputId": "fad26008-87bc-4117-fbfd-e893b552d6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1087, 100, 100, 3)\n",
            "(1087, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.constraints import maxnorm\n",
        "from keras.models import load_model\n",
        "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras import datasets, Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import  image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                            featurewise_center=False,              \n",
        "                            samplewise_center=False,               \n",
        "                            featurewise_std_normalization=False,   \n",
        "                            samplewise_std_normalization=False,    \n",
        "                            zca_whitening=False,                  \n",
        "                            zoom_range=[0.5,1.5],                  \n",
        "                            rotation_range=45,                     \n",
        "                            width_shift_range=0.5,                 \n",
        "                            height_shift_range=0.5,               \n",
        "                            horizontal_flip=False,                 \n",
        "                            vertical_flip=False,                  \n",
        "                            brightness_range=[0.5,1.5],            \n",
        "                            shear_range=45,\n",
        "                            fill_mode=\"nearest\")  \n",
        "\n",
        "DataGen = datagen.flow(x_train,y_train,batch_size=128)\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(64,64, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "\n",
        "# model.add(Dense(128, activation='relu',input_shape=(64*64*3,), name='layer1'))\n",
        "# model.add(Dense(128, activation='relu', name='layer2'))\n",
        "# model.add(Dense(256, activation='relu', name='layer3'))\n",
        "# model.add(Dense(512, activation='relu', name='layer4'))\n",
        "# model.add(Dense(1028, activation='relu', name='layer5'))\n",
        "# model.add(Dense(8, activation='softmax',name='layer6'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics = ['accuracy'])               \n",
        "\n",
        "# checkpoint = ModelCheckpoint('best_model_improved.h5',     # model filename\n",
        "#                              monitor='val_loss',           # quantity to monitor\n",
        "#                              verbose=1,                    # verbosity - 0 or 1\n",
        "#                              save_best_only= True,         # The latest best model will not be overwritten\n",
        "#                              mode='auto')                  # The decision to overwrite model is made \n",
        "#                                                            # automatically depending on the quantity to monitor \n",
        "                                                           \n",
        "# model.fit(x_train, y_train,\n",
        "#           epochs =1000,\n",
        "#           validation_data = (x_test, y_test),\n",
        "#           callbacks=[checkpoint],\n",
        "#           verbose=1)\n",
        "\n",
        "# model.save('data.h5')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32,\n",
        "                 kernel_size=(2,2),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_uniform',\n",
        "                 padding='same',\n",
        "                 input_shape=(100,100,3),\n",
        "                 strides=(1,1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                 kernel_size=(2,2),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 strides=(2,2)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128,\n",
        "                 kernel_size=(2,2),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=128,\n",
        "                 kernel_size=(2,2),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu',input_shape=(100*100*3,), name='layer1')) \n",
        "model.add(Dense(1028, activation='relu', name='layer2'))\n",
        "model.add(Dense(2056, activation='relu', name='layer3'))\n",
        "model.add(Dense(1028, activation='relu', name='layer4'))\n",
        "model.add(Dense(8, activation='softmax', name='layer5'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics = ['accuracy'])               \n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model_improved.h5',    \n",
        "                             monitor='val_loss',          \n",
        "                             verbose=1,                   \n",
        "                             save_best_only= True,        \n",
        "                             mode='auto')                  \n",
        "                                                           \n",
        "                                                          \n",
        "model.fit(x_train, y_train,\n",
        "          epochs =10,\n",
        "          validation_data = (x_test, y_test),\n",
        "          callbacks=[checkpoint],\n",
        "          verbose=1)\n",
        "model.save('data.h5')"
      ],
      "metadata": {
        "id": "H8kZnYvYPKap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_plot(history,0)"
      ],
      "metadata": {
        "id": "1jVT7p7FeHaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subject='body  parts'\n",
        "print_code=0\n",
        "preds=model.predict(test_gen) \n",
        "acc=print_info( test_gen, preds, print_code, working_dir, subject ) "
      ],
      "metadata": {
        "id": "6xI5e1tIC5BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Model123.h')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH2Z4XXhSmUv",
        "outputId": "0b43db42-3d8e-421d-db4e-90a871f605f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: MODEL.h/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(' model_body.h5')\n",
        "img = load_img('/content/drive/MyDrive/People_CNN/test/Nose_test.jpg', target_size=(100,100)) # test\n",
        "print ('Input image shape is ', img.shape)\n",
        "plt.imshow(img)\n",
        "img = img_to_array(img)\n",
        "img = img.reshape(1, 100, 100, 3)\n",
        "img = img.astype('float32')\n",
        "img /= 255 \n",
        "pred=model.predict(img)\n",
        "index=np.argmax(pred[0])\n",
        "klass=label[index]\n",
        "probability=pred[0][index]*100\n",
        "print(f'the image is predicted as being {klass} with a probability of {probability:6.2f} %')\n",
        "\n",
        "#['Ear', 'Elbow', 'Eye', 'Foot', 'Hand', 'Knee', 'Nose', 'Shoulders']\n",
        "Input image shape is  (177, 284, 3)\n",
        "the image is predicted as being Nose with a probability of 92.01 %\n"
      ],
      "metadata": {
        "id": "HUeARrtBfxzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}